{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "NHL2021 Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dwgb93/NHL-Stanley-Cup-Predictions/blob/main/2021/NHL2021_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3eFIoSsBVRZ",
        "outputId": "f99f4875-e914-428f-f729-63a2bdf06571"
      },
      "source": [
        "import xlrd\n",
        "import numpy as np # basically matlab\n",
        "import matplotlib.pyplot as plt # for plotting\n",
        "book = xlrd.open_workbook('HockeyData2021.xlsx')\n",
        "sheet = book.sheet_by_name('Sheet1')\n",
        "x_train = [[sheet.cell_value(r, c) for c in range(sheet.ncols-2)] for r in range(sheet.nrows)]\n",
        "\n",
        "# Profit !\n",
        "#print(x_data)\n",
        "\n",
        "#outputs\n",
        "y_data = [sheet.cell_value(rw, 20) for rw in range(sheet.nrows)]\n",
        "y_categorical = [sheet.cell_value(rw, 21) for rw in range(sheet.nrows)]\n",
        "#y_data = np.zeros((302,2))\n",
        "\n",
        "# sanity check\n",
        "print('x_data shape =', np.shape(x_train))\n",
        "print('y_data shape =',np.shape(y_data))\n",
        "#x = np.concatenate((np.ones(n)[:, np.newaxis], x_train),1)\n",
        "\n",
        "y_categorical"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_data shape = (176, 20)\n",
            "y_data shape = (176,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['b',\n",
              " 'a',\n",
              " 'e',\n",
              " 'a',\n",
              " 'b',\n",
              " 'a',\n",
              " 'c',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'd',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'b',\n",
              " 'a',\n",
              " 'a',\n",
              " 'e',\n",
              " 'a',\n",
              " 'a',\n",
              " 'b',\n",
              " 'a',\n",
              " 'a',\n",
              " 'b',\n",
              " 'a',\n",
              " 'b',\n",
              " 'a',\n",
              " 'a',\n",
              " 'c',\n",
              " 'c',\n",
              " 'd',\n",
              " 'b',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'e',\n",
              " 'b',\n",
              " 'd',\n",
              " 'c',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'a',\n",
              " 'a',\n",
              " 'b',\n",
              " 'a',\n",
              " 'b',\n",
              " 'a',\n",
              " 'd',\n",
              " 'e',\n",
              " 'b',\n",
              " 'c',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'b',\n",
              " 'b',\n",
              " 'c',\n",
              " 'b',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'b',\n",
              " 'b',\n",
              " 'c',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'e',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'a',\n",
              " 'b',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'c',\n",
              " 'b',\n",
              " 'e',\n",
              " 'a',\n",
              " 'b',\n",
              " 'b',\n",
              " 'a',\n",
              " 'a',\n",
              " 'c',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'd',\n",
              " 'a',\n",
              " 'b',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'b',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'b',\n",
              " 'b',\n",
              " 'a',\n",
              " 'a',\n",
              " 'e',\n",
              " 'd',\n",
              " 'c',\n",
              " 'c',\n",
              " 'b',\n",
              " 'c',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'b',\n",
              " 'a',\n",
              " 'a',\n",
              " 'd',\n",
              " 'b',\n",
              " 'c',\n",
              " 'e',\n",
              " 'a',\n",
              " 'b',\n",
              " 'a',\n",
              " 'b',\n",
              " 'a',\n",
              " 'b',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'b',\n",
              " 'a',\n",
              " 'a',\n",
              " 'b',\n",
              " 'b',\n",
              " 'c',\n",
              " 'a',\n",
              " 'd',\n",
              " 'e',\n",
              " 'c',\n",
              " 'd',\n",
              " 'a',\n",
              " 'c',\n",
              " 'b',\n",
              " 'b',\n",
              " 'b',\n",
              " 'a',\n",
              " 'b',\n",
              " 'a',\n",
              " 'c',\n",
              " 'e',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'b',\n",
              " 'a',\n",
              " 'a',\n",
              " 'a',\n",
              " 'b',\n",
              " 'a',\n",
              " 'd',\n",
              " 'a',\n",
              " 'c',\n",
              " 'b',\n",
              " 'a',\n",
              " 'e',\n",
              " 'b',\n",
              " 'c',\n",
              " 'a']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2zfauuCBVRe",
        "outputId": "7ba1f82a-96ed-4d41-e65a-e6d57cf3acd4"
      },
      "source": [
        "sheet2 = book.sheet_by_name('Sheet2')\n",
        "x_test = [[sheet2.cell_value(r, c) for c in range(sheet2.ncols)] for r in range(sheet2.nrows)]\n",
        "\n",
        "# Profit !\n",
        "print(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.5580158054338478, -1.9840550878589673, 1.6636844874373882, 1.8132993694661321, 0.7569844647766205, -2.1467262865896686, 1.4995240554716294, 1.4285535333451918, 1.3794120177259797, 1.1807060721361502, 0.4449002273473756, -0.9142973921834366, 0.5313562255807787, 2.048217031471925, 1.5616843234157578, -0.18066593070662326, -0.7035151488798027, 1.9798899582857568, 2.0916801491867596, 1.5940630265421438], [0.5303883592966288, -0.28414859298482714, -1.295492018906163, 0.4408497329035191, 0.6077632227034914, -0.5095460248166552, 0.6653210072853704, 1.3302876468059153, 0.9230716954776478, 1.6644314673284961, 1.2182781926428137, -1.3714460882751527, 0.2690625473482312, 0.6827390104906447, 0.9546633045037911, 0.05238099467467587, 0.5548109759404369, 0.2250320787690674, -0.371355451555066, 0.956700285139316], [1.215473323388108, -1.0568333633821636, -0.027273516187498143, 1.1503364094316502, 1.1282177987146504, -0.957984443779551, -0.2551789079546399, 0.47864996346551414, -0.09698314248920939, 0.7292290366232967, 0.5093483911219966, -0.06530695658453417, -0.2030660734703536, 0.34136950524532234, 0.5581169102396923, -0.7294538517658096, 0.06478974464024824, 0.18159500254340694, -0.047827326426349424, 0.12948481225479488], [0.35911711827375886, -0.28414859298482714, 0.39546598471872346, 0.3129095125459872, 0.462437828929075, 0.17761707170347493, 2.7364458165753938, 1.461308828858287, 2.0236571785471527, 0.9549675543797257, -1.1663038670181263, 0.3918417395071818, -0.5178184873494114, -1.7068475262265994, 0.20427551228095833, -0.6542774242234555, 1.135576879703625, -2.494128892957287, -2.310114920464631, -1.1859233987255093], [0.01657463622801919, -0.12961163890535984, -0.027273516187498143, 0.0802909300777475, 0.9345308418774174, 0.9670732348732536, 0.37766478377286705, -0.4712536064141681, 0.5472620183319636, -0.7219471489537411, 0.831589209995097, 0.5877626092607727, 0.1641450760552107, -0.640067822334973, 0.07005980960695649, -1.0000889909182864, 0.19183228608844494, -0.39177440363531335, -0.5287326253985376, 0.25153299677874064], [0.01657463622801919, 0.024925315174107468, -0.45001301709371977, -0.0011255737861351025, 0.5160713672290739, 0.6000388914725243, 0.37766478377286705, -0.8970724480843687, 0.4130442764942192, -1.3991627022230282, -0.8440630481450259, -0.45714869609172065, -0.8325709012284691, -0.640067822334973, 0.08531159400172972, 0.5936512729796283, 0.07083938947111465, 0.7723392392123911, 0.359527750350092, -1.1588015799424103], [-0.6685103278634602, 0.6430731314919766, 0.39546598471872346, -0.6757194629440303, -0.14756999679069177, 0.43239946299774334, -0.6578976208721451, -0.4057430153879823, -0.49963636800244327, -0.4639602715178242, 1.733863502839777, -0.19592086975359557, 0.21660381170172094, -1.4081492091369427, 0.08836195088068372, 1.0447098382337547, 1.4441087660778182, 0.7375895782318633, -0.6017423892598529, -0.3587079258409881], [0.01657463622801919, -0.12961163890535984, -0.027273516187498143, 0.0802909300777475, 0.26499568244006827, 0.4427384585864968, -0.772960110277146, -1.2573806987283882, -0.8754460451481278, -1.3024176231845555, 1.0893818650935763, -0.06530695658453417, 1.2133197889854008, 0.384040693400988, 0.006002315148909547, -1.127888917740289, -0.2558414313956789, -0.7045213524600701, -0.43040055148729145, -0.819778845153672], [0.01657463622801919, -0.5932225011437617, 0.8182054856249451, 0.3478022999162232, -0.5811539905620957, -0.6691596993627718, -0.772960110277146, 0.2493628948738662, -0.7143847549428342, 0.3744970801489069, -1.1663038670181263, -0.13061391316906604, -0.04568986653082657, 1.3228068328256206, -0.2227744507726857, -1.0076066336725218, -0.1348485347783475, -1.773073427611321, -1.284497341485062, 1.648306664108342], [0.8729308413423684, -0.5932225011437617, -0.8727525179999414, 0.7548848192356427, 0.6416092096235774, -0.5010641387296634, -0.0250539291446381, 0.7079370320571574, 0.14460879281873026, 0.7614773963027845, 0.31600389979813365, -1.11021826193703, -0.5702772229959215, -0.6827390104906386, -0.5827165624893288, 1.5483919027675292, -1.1027917077169935, -0.3483373274096529, 0.6382613651469001, 0.2786548155618397], [1.215473323388108, -1.211370317461631, 0.8182054856249451, 1.20849105504871, 0.462437828929075, -1.0962948847678688, 1.2406334543103767, -0.2092112423094296, 1.1646636307855884, -0.3672151924793559, -0.45737406549730675, -1.1755252185215594, 0.8461086394598365, 0.6827390104906447, -0.9304572466901538, 0.796627627343985, -1.175387445687392, 0.6767776715159383, 1.626552335527198, -0.07392882861844802], [1.386744564410978, -0.9022964093026963, -0.8727525179999414, 1.1503364094316502, 1.4169548362220075, -0.751246731986488, 0.8954459860953732, 0.47864996346551414, 0.762010405272355, 0.342248720469419, -0.1995814103988251, -0.32653478292265925, 0.2690625473482312, 0.128013564466997, -1.0433204512114744, -0.27839528651168327, 0.8633428623146301, 1.1458980947530721, -0.005892413861629755, 0.9838221039224151], [0.18784587725088903, -0.28414859298482714, 0.39546598471872346, 0.2431239378055153, 1.169465946929987, 0.6959172505649583, 0.8954459860953732, -0.7332959705189066, 0.6814797601697081, -0.8509405876717019, 0.9604855375443344, 0.32653478292265, 1.3182372602784211, -0.08534237631132831, -1.0738240200010198, 0.3756396331067997, 1.0629811417332258, 1.3891457216167726, 0.006464782999929997, -0.819778845153672], [0.7016596003194986, -0.4386855470642944, -0.027273516187498143, 0.557159024137639, 0.5031050173103928, -0.1281217978496472, 0.5790241402316192, -1.093604221162926, 0.9230716954776478, -0.6896987892742532, 1.9916561579382563, -1.3714460882751527, 0.006768869115683671, 1.8348610906935994, -1.2598957896172505, -1.6090180540113566, 0.4096194999996399, 1.5715814417645464, 0.6126487491441492, 0.8075302818322713], [1.0442020823652383, -1.0568333633821636, -0.027273516187498143, 1.0921817638145903, 1.269298421596092, 0.3378715033291451, -0.16888204090088973, 0.8717135096226195, -0.4459492712673452, 0.6969806769438043, 0.38045206357275463, -0.7836834790143753, -0.8850296368749794, 0.384040693400988, -1.4795214849019827, 0.796627627343985, -0.48572793496860667, 0.1642201720531423, 0.4187350169439924, 1.187235744795658], [0.35911711827375886, 0.17946226925357478, -0.8727525179999414, 0.05702907183092353, 0.05576594511589716, -0.5357736239204783, 0.14753980496286426, -0.7660512660320018, 0.5472620183319636, -0.6252020699152728, -0.07068508284958541, 0.7836834790143683, 0.059227604762193915, -0.17068475262265662, -1.6167875444549396, 0.2779102773017397, -2.064685235824773, -0.7479584286857306, 1.5769192207405573, -0.3722688352325376]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqqU1eNrBVRf",
        "outputId": "19ef1506-2810-4f74-ff21-cc98ad96036d"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "# get dimensions\n",
        "N = len(x_train) # number of data points\n",
        "Nt = len(x_test)\n",
        "input_dim = len(np.transpose(x_train)) # number of input features\n",
        "output_dim = 1\n",
        "print(input_dim)\n",
        "\n",
        "epochs = 100 # total number of epochs\n",
        "neurons = 64 # number of neurons in the hidden layer\n",
        "\n",
        "# define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(neurons, input_dim=input_dim, activation='linear'))\n",
        "model.add(Dense(neurons, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(neurons, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(output_dim))\n",
        "\n",
        "# set the loss function\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['accuracy']) #loss mean_squared_error? categorical?\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                1344      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 9,729\n",
            "Trainable params: 9,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPyKBLWiDjWv",
        "outputId": "12c0693a-2c40-472a-b230-10530fc83f61"
      },
      "source": [
        "y_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.25,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 0.5,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.75,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.5,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.5,\n",
              " 0.5,\n",
              " 0.75,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.25,\n",
              " 0.75,\n",
              " 0.5,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.5,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 0.75,\n",
              " 1.0,\n",
              " 0.25,\n",
              " 0.5,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.25,\n",
              " 0.5,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.25,\n",
              " 0.5,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.25,\n",
              " 0.5,\n",
              " 0.75,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.5,\n",
              " 0.25,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.5,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.75,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.75,\n",
              " 0.5,\n",
              " 0.5,\n",
              " 0.25,\n",
              " 0.5,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.75,\n",
              " 0.25,\n",
              " 0.5,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.25,\n",
              " 0.5,\n",
              " 0.0,\n",
              " 0.75,\n",
              " 1.0,\n",
              " 0.5,\n",
              " 0.75,\n",
              " 0.0,\n",
              " 0.5,\n",
              " 0.25,\n",
              " 0.25,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 0.5,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 0.75,\n",
              " 0.0,\n",
              " 0.5,\n",
              " 0.25,\n",
              " 0.0,\n",
              " 1.0,\n",
              " 0.25,\n",
              " 0.5,\n",
              " 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyjSDsQMBVRh",
        "outputId": "58cba445-54b5-476f-f135-d844f98ea212"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "#Save the best model.\n",
        "model_checkpoint = ModelCheckpoint('best_NHL_model.hdf5', monitor='val_loss', save_best_only=True, save_freq='epoch')\n",
        "callbacks_list=[model_checkpoint]\n",
        "\n",
        "model.fit(x=np.array(x_train),y=np.array(y_data), batch_size=16,epochs=epochs,verbose=1,validation_split=0.5,callbacks=callbacks_list)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 1s 51ms/step - loss: 0.0319 - accuracy: 0.5455 - val_loss: 0.0333 - val_accuracy: 0.5455\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0319 - accuracy: 0.5341 - val_loss: 0.0326 - val_accuracy: 0.5455\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0335 - accuracy: 0.5341 - val_loss: 0.0325 - val_accuracy: 0.5455\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0359 - accuracy: 0.5568 - val_loss: 0.0338 - val_accuracy: 0.5455\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0323 - accuracy: 0.5568 - val_loss: 0.0354 - val_accuracy: 0.5455\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0283 - accuracy: 0.5455 - val_loss: 0.0368 - val_accuracy: 0.5455\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0392 - accuracy: 0.5341 - val_loss: 0.0383 - val_accuracy: 0.5455\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0300 - accuracy: 0.5455 - val_loss: 0.0402 - val_accuracy: 0.5455\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0351 - accuracy: 0.5341 - val_loss: 0.0423 - val_accuracy: 0.5341\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0345 - accuracy: 0.5455 - val_loss: 0.0433 - val_accuracy: 0.5341\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0486 - accuracy: 0.5227 - val_loss: 0.0434 - val_accuracy: 0.5341\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0446 - accuracy: 0.5341 - val_loss: 0.0446 - val_accuracy: 0.5341\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0367 - accuracy: 0.5455 - val_loss: 0.0456 - val_accuracy: 0.5341\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0351 - accuracy: 0.5341 - val_loss: 0.0453 - val_accuracy: 0.5341\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0326 - accuracy: 0.5341 - val_loss: 0.0451 - val_accuracy: 0.5341\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0343 - accuracy: 0.5568 - val_loss: 0.0449 - val_accuracy: 0.5341\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0383 - accuracy: 0.5455 - val_loss: 0.0454 - val_accuracy: 0.5341\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0204 - accuracy: 0.5568 - val_loss: 0.0471 - val_accuracy: 0.5227\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0329 - accuracy: 0.5341 - val_loss: 0.0481 - val_accuracy: 0.5227\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0321 - accuracy: 0.5455 - val_loss: 0.0479 - val_accuracy: 0.5227\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0265 - accuracy: 0.5568 - val_loss: 0.0508 - val_accuracy: 0.5227\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0289 - accuracy: 0.5341 - val_loss: 0.0526 - val_accuracy: 0.5227\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0368 - accuracy: 0.5227 - val_loss: 0.0527 - val_accuracy: 0.5227\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0308 - accuracy: 0.5568 - val_loss: 0.0523 - val_accuracy: 0.5227\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0274 - accuracy: 0.5455 - val_loss: 0.0525 - val_accuracy: 0.5227\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0195 - accuracy: 0.5568 - val_loss: 0.0529 - val_accuracy: 0.5227\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0385 - accuracy: 0.5455 - val_loss: 0.0534 - val_accuracy: 0.5227\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0267 - accuracy: 0.5568 - val_loss: 0.0539 - val_accuracy: 0.5341\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0311 - accuracy: 0.5341 - val_loss: 0.0529 - val_accuracy: 0.5341\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0282 - accuracy: 0.5455 - val_loss: 0.0537 - val_accuracy: 0.5341\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0190 - accuracy: 0.5568 - val_loss: 0.0548 - val_accuracy: 0.5341\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0345 - accuracy: 0.5341 - val_loss: 0.0549 - val_accuracy: 0.5341\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0229 - accuracy: 0.5455 - val_loss: 0.0556 - val_accuracy: 0.5341\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0317 - accuracy: 0.5568 - val_loss: 0.0556 - val_accuracy: 0.5341\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0279 - accuracy: 0.5568 - val_loss: 0.0574 - val_accuracy: 0.5227\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0273 - accuracy: 0.5568 - val_loss: 0.0586 - val_accuracy: 0.5227\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0259 - accuracy: 0.5455 - val_loss: 0.0573 - val_accuracy: 0.5227\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0232 - accuracy: 0.5568 - val_loss: 0.0564 - val_accuracy: 0.5227\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0224 - accuracy: 0.5568 - val_loss: 0.0552 - val_accuracy: 0.5227\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0208 - accuracy: 0.5568 - val_loss: 0.0554 - val_accuracy: 0.5227\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0233 - accuracy: 0.5568 - val_loss: 0.0553 - val_accuracy: 0.5227\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0213 - accuracy: 0.5568 - val_loss: 0.0540 - val_accuracy: 0.5227\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0242 - accuracy: 0.5568 - val_loss: 0.0538 - val_accuracy: 0.5227\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0260 - accuracy: 0.5455 - val_loss: 0.0550 - val_accuracy: 0.5227\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0221 - accuracy: 0.5568 - val_loss: 0.0572 - val_accuracy: 0.5227\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0271 - accuracy: 0.5455 - val_loss: 0.0574 - val_accuracy: 0.5227\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0273 - accuracy: 0.5455 - val_loss: 0.0581 - val_accuracy: 0.5227\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0165 - accuracy: 0.5568 - val_loss: 0.0597 - val_accuracy: 0.5227\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0164 - accuracy: 0.5568 - val_loss: 0.0615 - val_accuracy: 0.5227\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0374 - accuracy: 0.5341 - val_loss: 0.0628 - val_accuracy: 0.5227\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0270 - accuracy: 0.5341 - val_loss: 0.0640 - val_accuracy: 0.5227\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0284 - accuracy: 0.5455 - val_loss: 0.0625 - val_accuracy: 0.5227\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0251 - accuracy: 0.5568 - val_loss: 0.0619 - val_accuracy: 0.5227\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0189 - accuracy: 0.5568 - val_loss: 0.0625 - val_accuracy: 0.5227\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0227 - accuracy: 0.5568 - val_loss: 0.0622 - val_accuracy: 0.5227\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0217 - accuracy: 0.5568 - val_loss: 0.0630 - val_accuracy: 0.5227\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0268 - accuracy: 0.5568 - val_loss: 0.0627 - val_accuracy: 0.5227\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0184 - accuracy: 0.5455 - val_loss: 0.0613 - val_accuracy: 0.5341\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0238 - accuracy: 0.5568 - val_loss: 0.0608 - val_accuracy: 0.5341\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0211 - accuracy: 0.5568 - val_loss: 0.0604 - val_accuracy: 0.5341\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0214 - accuracy: 0.5568 - val_loss: 0.0617 - val_accuracy: 0.5341\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0304 - accuracy: 0.5341 - val_loss: 0.0627 - val_accuracy: 0.5341\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0265 - accuracy: 0.5455 - val_loss: 0.0625 - val_accuracy: 0.5227\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.5568 - val_loss: 0.0626 - val_accuracy: 0.5227\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.5455 - val_loss: 0.0619 - val_accuracy: 0.5227\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0166 - accuracy: 0.5568 - val_loss: 0.0622 - val_accuracy: 0.5227\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0156 - accuracy: 0.5568 - val_loss: 0.0634 - val_accuracy: 0.5227\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0280 - accuracy: 0.5341 - val_loss: 0.0625 - val_accuracy: 0.5227\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0302 - accuracy: 0.5455 - val_loss: 0.0619 - val_accuracy: 0.5341\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0246 - accuracy: 0.5455 - val_loss: 0.0623 - val_accuracy: 0.5227\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0291 - accuracy: 0.5568 - val_loss: 0.0631 - val_accuracy: 0.5227\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0189 - accuracy: 0.5568 - val_loss: 0.0636 - val_accuracy: 0.5227\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0255 - accuracy: 0.5568 - val_loss: 0.0660 - val_accuracy: 0.5227\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0241 - accuracy: 0.5341 - val_loss: 0.0656 - val_accuracy: 0.5227\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0201 - accuracy: 0.5568 - val_loss: 0.0639 - val_accuracy: 0.5227\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0220 - accuracy: 0.5455 - val_loss: 0.0620 - val_accuracy: 0.5227\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0221 - accuracy: 0.5568 - val_loss: 0.0610 - val_accuracy: 0.5227\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.5568 - val_loss: 0.0617 - val_accuracy: 0.5227\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0257 - accuracy: 0.5341 - val_loss: 0.0622 - val_accuracy: 0.5227\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0162 - accuracy: 0.5568 - val_loss: 0.0618 - val_accuracy: 0.5341\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0217 - accuracy: 0.5568 - val_loss: 0.0614 - val_accuracy: 0.5341\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0138 - accuracy: 0.5568 - val_loss: 0.0627 - val_accuracy: 0.5341\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0250 - accuracy: 0.5455 - val_loss: 0.0647 - val_accuracy: 0.5227\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0252 - accuracy: 0.5455 - val_loss: 0.0659 - val_accuracy: 0.5227\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0214 - accuracy: 0.5455 - val_loss: 0.0666 - val_accuracy: 0.5227\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0184 - accuracy: 0.5568 - val_loss: 0.0671 - val_accuracy: 0.5227\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0319 - accuracy: 0.5341 - val_loss: 0.0671 - val_accuracy: 0.5227\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0237 - accuracy: 0.5568 - val_loss: 0.0659 - val_accuracy: 0.5227\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0190 - accuracy: 0.5568 - val_loss: 0.0646 - val_accuracy: 0.5227\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0205 - accuracy: 0.5568 - val_loss: 0.0635 - val_accuracy: 0.5227\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0289 - accuracy: 0.5227 - val_loss: 0.0632 - val_accuracy: 0.5227\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0245 - accuracy: 0.5455 - val_loss: 0.0630 - val_accuracy: 0.5341\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0243 - accuracy: 0.5568 - val_loss: 0.0642 - val_accuracy: 0.5227\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0247 - accuracy: 0.5455 - val_loss: 0.0663 - val_accuracy: 0.5227\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0181 - accuracy: 0.5568 - val_loss: 0.0684 - val_accuracy: 0.5227\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0306 - accuracy: 0.5568 - val_loss: 0.0725 - val_accuracy: 0.5227\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0186 - accuracy: 0.5455 - val_loss: 0.0725 - val_accuracy: 0.5227\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0266 - accuracy: 0.5455 - val_loss: 0.0708 - val_accuracy: 0.5227\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0194 - accuracy: 0.5455 - val_loss: 0.0677 - val_accuracy: 0.5227\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0214 - accuracy: 0.5568 - val_loss: 0.0675 - val_accuracy: 0.5227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f43b48e5c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqgQNQOZBVRi",
        "outputId": "460b4573-3d4f-4f5e-ce97-f3b939167286"
      },
      "source": [
        "model.load_weights('best_NHL_model.hdf5')\n",
        "predict = model.predict(np.array(x_test))\n",
        "predict\n",
        "Y = np.exp(predict[:,0])/np.sum(np.exp(predict[:,0]))\n",
        "Y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.10185367, 0.06964913, 0.06821276, 0.05404677, 0.0504855 ,\n",
              "       0.05443486, 0.05027695, 0.05130076, 0.06871438, 0.06024291,\n",
              "       0.0806284 , 0.06432152, 0.05405093, 0.05608917, 0.06470984,\n",
              "       0.05098245], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reN51nEYBVRk"
      },
      "source": [
        "teamlist = [\"Boston Bruins\",\n",
        "\"Carolina Hurricanes\",\n",
        "\"Colorado Avalanche\",\n",
        "\"Edmonton Oilers\",\n",
        "\"Florida Panthers\",\n",
        "\"Minnesota Wild\",\n",
        "\"Montréal Canadiens\",\n",
        "\"Nashville Predators\",\n",
        "\"New York Islanders\",\n",
        "\"Pittsburgh Penguins\",\n",
        "\"St. Louis Blues\",\n",
        "\"Tampa Bay Lightning\",\n",
        "\"Toronto Maple Leafs\",\n",
        "\"Vegas Golden Knights\",\n",
        "\"Washington Capitals\",\n",
        "\"Winnipeg Jets\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBWIXpqEBVRl",
        "outputId": "db441145-4e7a-4954-cc08-34c5b3c2e4ac"
      },
      "source": [
        "Z = [x for _,x in sorted(zip(Y,teamlist))]\n",
        "Z.reverse()\n",
        "Z"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Boston Bruins',\n",
              " 'St. Louis Blues',\n",
              " 'Carolina Hurricanes',\n",
              " 'New York Islanders',\n",
              " 'Colorado Avalanche',\n",
              " 'Washington Capitals',\n",
              " 'Tampa Bay Lightning',\n",
              " 'Pittsburgh Penguins',\n",
              " 'Vegas Golden Knights',\n",
              " 'Minnesota Wild',\n",
              " 'Toronto Maple Leafs',\n",
              " 'Edmonton Oilers',\n",
              " 'Nashville Predators',\n",
              " 'Winnipeg Jets',\n",
              " 'Florida Panthers',\n",
              " 'Montréal Canadiens']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnUBSUJhBVRm",
        "outputId": "5f4625a7-c1d4-41f0-e754-f71d48c52ca8"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression(penalty='l2',solver='lbfgs').fit(x_train, y_categorical)\n",
        "clf.score(x_train, y_categorical)\n",
        "\n",
        "\n",
        "#Basically, it's just guessing that EVERY team won't win, and 58% of the time, it's right! Oof."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5795454545454546"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Lpww15uBVRn",
        "outputId": "c03a990f-c7bd-4d19-da96-25f47e60ee4d"
      },
      "source": [
        "clf.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['b', 'b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'b', 'b', 'a', 'a',\n",
              "       'a', 'a', 'a'], dtype='<U1')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJltX6jtBVRn",
        "outputId": "f4ca5a22-5970-4edb-9261-f942ebba3bad"
      },
      "source": [
        "Y2_log = clf.predict_log_proba(x_test)\n",
        "Y2 = clf.predict_proba(x_test)\n",
        "Y2[:,-1]\n",
        "#That's it - we want either want straight probabilities, or to exponentiate the log probabilities"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.22424592, 0.03291882, 0.15988081, 0.00153162, 0.00546801,\n",
              "       0.00319555, 0.00842592, 0.06218794, 0.02139455, 0.01238015,\n",
              "       0.03745299, 0.02631188, 0.01987706, 0.06445982, 0.01570699,\n",
              "       0.01554335])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uykELPWIBVRo",
        "outputId": "62d0c58b-66e0-4c10-f701-ed156016c675"
      },
      "source": [
        "Y2_log = np.exp(Y2_log[:,-1])\n",
        "Y2_log #By looking at the predicted probability of winning, we can rank the teams\n",
        "#This should be the same as the output of the cell above"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.22424592, 0.03291882, 0.15988081, 0.00153162, 0.00546801,\n",
              "       0.00319555, 0.00842592, 0.06218794, 0.02139455, 0.01238015,\n",
              "       0.03745299, 0.02631188, 0.01987706, 0.06445982, 0.01570699,\n",
              "       0.01554335])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKOyt__zBVRp",
        "outputId": "5696f7ed-b827-4b81-90ec-56ae61a39ea4"
      },
      "source": [
        "Z2 = [x for _,x in sorted(zip(Y2_log,teamlist))]\n",
        "Z2.reverse()\n",
        "Z2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Boston Bruins',\n",
              " 'Colorado Avalanche',\n",
              " 'Vegas Golden Knights',\n",
              " 'Nashville Predators',\n",
              " 'St. Louis Blues',\n",
              " 'Carolina Hurricanes',\n",
              " 'Tampa Bay Lightning',\n",
              " 'New York Islanders',\n",
              " 'Toronto Maple Leafs',\n",
              " 'Washington Capitals',\n",
              " 'Winnipeg Jets',\n",
              " 'Pittsburgh Penguins',\n",
              " 'Montréal Canadiens',\n",
              " 'Florida Panthers',\n",
              " 'Minnesota Wild',\n",
              " 'Edmonton Oilers']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIGID-yeBVRp",
        "outputId": "152fd161-b2ae-488a-f8da-fb2846c7ae67"
      },
      "source": [
        "losers = Y2[:,0]\n",
        "Z3 = [x for _,x in sorted(zip(losers,teamlist))]\n",
        "Z3.reverse()\n",
        "Z3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Florida Panthers',\n",
              " 'Winnipeg Jets',\n",
              " 'Nashville Predators',\n",
              " 'Minnesota Wild',\n",
              " 'New York Islanders',\n",
              " 'Vegas Golden Knights',\n",
              " 'Montréal Canadiens',\n",
              " 'Edmonton Oilers',\n",
              " 'Toronto Maple Leafs',\n",
              " 'Washington Capitals',\n",
              " 'Colorado Avalanche',\n",
              " 'Tampa Bay Lightning',\n",
              " 'Pittsburgh Penguins',\n",
              " 'Carolina Hurricanes',\n",
              " 'St. Louis Blues',\n",
              " 'Boston Bruins']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    }
  ]
}